#!/usr/bin/env bash
set -euo pipefail
# â”€â”€ start.sh â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# â€¢ Creates/updates the venv and installs requirements
# â€¢ Optionally regenerates the CSV & script catalogues (interactive prompts)
# â€¢ Regenerates gRPC stubs into the repo root
# â€¢ Launches FastAPI (no reload) while an external LLM micro-service runs
#   via ./start_llm.sh

# 0) Move to repo root ------------------------------------------------------------
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" &>/dev/null && pwd)"
cd "$SCRIPT_DIR"

VENV_DIR=".venv"

# 1) Create venv if missing -------------------------------------------------------
if [[ ! -d "$VENV_DIR" ]]; then
  echo "ğŸ  Creating virtualenv in $VENV_DIR â€¦"
  python -m venv "$VENV_DIR"
fi

# 2) Activate venv (handles Windows & POSIX layouts) -----------------------------
if [[ -f "$VENV_DIR/Scripts/activate" ]]; then     # Windows
  source "$VENV_DIR/Scripts/activate"
elif [[ -f "$VENV_DIR/bin/activate" ]]; then       # Linux/macOS/WSL
  source "$VENV_DIR/bin/activate"
else
  echo "âŒ  Could not find activate script in $VENV_DIR" >&2
  exit 1
fi

# 3) Upgrade pip & install/upgrade deps ------------------------------------------
echo "â¬†ï¸  Upgrading pip & wheel â€¦"
python -m pip install --upgrade --quiet pip wheel

echo "ğŸ“¦ Installing requirements.txt â€¦"
pip install --no-cache-dir -r requirements.txt

# 4) Regenerate gRPC stubs into the root directory -------------------------------
echo "ğŸ› ï¸  Generating gRPC Python stubs in ./"
python -m grpc_tools.protoc \
  -I proto \
  --python_out=. \
  --grpc_python_out=. \
  proto/model.proto

# 5) Load .env if present --------------------------------------------------------
if [[ -f ".env" ]]; then
  echo "ğŸ“„  Loading .env"
  set -a
  source .env
  set +a
fi

# 6) Optional catalogue regeneration ---------------------------------------------
regen() {
  local prompt="$1" pycall="$2" answer
  read -rp "$prompt (Y/N): " answer
  answer=${answer^^}
  if [[ "$answer" == "Y" ]]; then
    echo "ğŸ”„  Regenerating â€¦"
    python - <<PY
import importlib
mod, fn = "$pycall".rsplit(".",1)
getattr(importlib.import_module(mod), fn)()
PY
  else
    echo "â­ï¸  Skipped"
  fi
}
regen "Regenerate CSV catalogue?"    "app.services.catalog_generation.csv_cat.save_csv_catalog"
regen "Regenerate script catalogue?" "app.services.catalog_generation.script_cat.save_script_catalog"

# 7) Launch FastAPI (no reload; LLM runs in separate process) ---------------------
echo "ğŸš€  Starting FastAPI on http://localhost:8000  (no reload)"
uvicorn app.main:app \
  --host 0.0.0.0 \
  --port 8000
